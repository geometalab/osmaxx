version: '3.7'
# for local development

# to run python tests:
# docker-compose run --rm -e DJANGO_SETTINGS_MODULE=config.settings django  python manage.py test

# setup project locally (migrations and static files):
# docker-compose run --rm frontend ./manage.py migrate --noinput
# docker-compose run --rm frontend ./manage.py collectstatic --noinput
# docker-compose run --rm mediator ./manage.py migrate --noinput
# docker-compose run --rm mediator ./manage.py collectstatic --noinput

services:

  access-rights:
    image: ubuntu:latest
    command: bash -c 'chown -R 1000 /access'
    user: root
    volumes:
      - frontend-media:/access/media
      - frontend-static:/access/static
      - worker-data:/access/job_result_files
      - worker-data-ignored:/access/ignored-worker
    logging: &logging
      driver: json-file
      options:
        max-size: 50m

  proxy:
    image: geometalab/env-configurable-caddy:latest
    environment:
      # See https://caddyserver.com/docs/quick-starts/caddyfile for details
      CADDY_CONFIG: |
        :8080 {
          route {
            handle /media/* {
              uri strip_prefix /media
              file_server /* {
                root /data/media/
                browse
              }
            }
            handle /static/* {
              uri strip_prefix /static
              file_server /* {
                root /data/static/
                browse
              }
            }
            reverse_proxy /* {
              to frontend:8000
            }
          }
        }
    volumes:
      - frontend-static:/data/static
      - frontend-media:/data/media
      - worker-data:/data/media/job_result_files
    ports:
    - 0.0.0.0:8080:8080/tcp
    networks:
      - default
    logging:
      <<: *logging
  ##### frontend START ########
  frontend: &frontend
    image: geometalab/osmaxx-frontend:latest
    build:
      context: .
      dockerfile: Dockerfile
      target: frontend
    entrypoint: dockerize -wait tcp://frontenddatabase:5432 -timeout 60s
    command: ./manage.py runserver_plus 0.0.0.0:8000
    user: "1000"
    volumes:
      # - ./osmaxx:/home/py/osmaxx/osmaxx
      # - ./web_frontend:/home/py/osmaxx/web_frontend
      - frontend-media:/data/media
      - frontend-static:/data/static
      - worker-data:/data/media/job_result_files
      - osm_data:/var/data/osm-planet
    environment: &baseenv
      ? DJANGO_ALLOWED_HOSTS=*
      ? DJANGO_SECRET_KEY=insecure!1
      ? DJANGO_SETTINGS_MODULE=config.settings
      ? DJANGO_DEBUG=false
      # set the following two lines if you want to be able to log in using OSM
      # but don't commit them!
      ? SOCIAL_AUTH_OPENSTREETMAP_KEY=
      ? SOCIAL_AUTH_OPENSTREETMAP_SECRET=
#     Allow access from any private-use IP, since docker assigns "random" IPs.
#     172.*.*.* is actually allowing too much, but this docker-compose file should
#     only ever be used on local development machine, anyway!
      ? DJANGO_INTERNAL_IPS=172.*.*.*,10.*.*.*,192.168.*.*,127.0.0.1
      ? DJANGO_DEFAULT_FROM_EMAIL=webmaster@osmaxx.exmaple.com
      ? DJANGO_SERVER_EMAIL=webmaster@osmaxx.exmaple.com
      ? OSMAXX_ACCOUNT_MANAGER_EMAIL=webmaster@osmaxx.exmaple.com
      ? DJANGO_LOG_LEVEL=INFO
      ? DJANGO_EMAIL_BACKEND=django.core.mail.backends.console.EmailBackend
      ? DJANGO_CSRF_COOKIE_SECURE=false
      ? DJANGO_SESSION_COOKIE_SECURE=false
      ? DJANGO_DATABASE_URL=postgis://frontend:insecureChangeInProduction!@frontenddatabase/frontend
      ? CELERY_BROKER_URL=redis://redis:6379/1
    networks:
      - default
    logging:
      <<: *logging
  frontend-setup:
    <<: *frontend
    command: bash -c "./manage.py migrate --noinput && ./manage.py collectstatic --noinput"
  frontend-purge-files:
    <<: *frontend
    command: ./manage.py purge_expired_result_files
  frontenddatabase:
    image: postgis/postgis:13-3.1
    volumes:
      - frontend-database-data:/database/data
    environment:
      - PGDATA=/database/data
      - POSTGRES_DB=frontend
      - POSTGRES_USER=frontend
      - POSTGRES_PASSWORD=insecureChangeInProduction!
    networks:
      - default
    logging:
      <<: *logging
  redis:
    image: redis
    networks:
      - default
    logging:
      <<: *logging

  worker: &worker
    <<: *frontend
    image: geometalab/osmaxx-worker:latest
    build:
      context: .
      dockerfile: Dockerfile
      target: worker
    entrypoint: dockerize -wait tcp://worker-db:5432 -timeout 60s
    user: "1000"
    command: celery -A config worker -l INFO
    environment: 
      <<: *baseenv
      ? DJANGO_SECRET_KEY=insecure!3
      ? GIS_CONVERSION_DB_HOST=worker-db
      # needs to be the password of the conversion db!
      ? PGPASSWORD=worker
      ? GIS_CONVERSION_DB_PASSWORD=worker
      ? GIS_CONVERSION_DB_USER=worker
      ? OSM_BOUNDARIES_DB_NAME=osmboundaries 
      ? DJANGO_DEBUG=false
      # set this at maximum your availbale number of cores
      ? CELERY_WORKER_CONCURRENCY=4
    networks:
      - default
    logging:
      <<: *logging
  scheduler:
    <<: *worker
    command: celery -A config beat -l INFO --scheduler django_celery_beat.schedulers:DatabaseScheduler

  worker-db:
    image: geometalab/osmaxx-worker-db:latest
    build:
      context: docker-helper-images/osmaxx-postgis-translit/
      dockerfile: Dockerfile
    # this can and probably should be further optimized
    # see https://www.postgresql.org/docs/current/app-postgres.html
    command: postgres --shared_buffers=2GB --synchronous_commit=off --full_page_writes=off --fsync=off --max_wal_size=10GB --autovacuum=off --checkpoint_timeout=360
    # command: postgres -B 1GB -F -S 1GB --max_wal_size=10GB
    volumes:
      - worker-db:/database
    environment:
      - PGDATA=/database/data
      - POSTGRES_DB=worker
      - POSTGRES_USER=worker
      - POSTGRES_PASSWORD=worker
    logging:
      <<: *logging

  osmboundaries-importer:
    # to build/update this image see `docker-helper-images/osmboundaries/`
    image: geometalab/osmboundaries:latest
    environment:
      # TODO: make osmboundaries more flexible concerning the database name
      # db-name must be osmboundaries. this is a hard-coded dependency
      - POSTGRES_DB=osmboundaries
      # the same as the ones in the database above
      - POSTGRES_USER=worker
      - POSTGRES_PASSWORD=worker
      - POSTGRES_HOST=worker-db
    networks:
      - default
    logging:
      <<: *logging

  ##### CONVERSION SERVICE END ########
  ##### WORLD PBF UPDATER START ########
  osm-pbf-updater:
    image: geometalab/osmaxx-osm-pbf-updater:latest
    build:
      context: docker-helper-images/osm_pbf_updater/
      dockerfile: Dockerfile
    volumes:
      - osm_data:/var/data/osm-planet
    entrypoint: /bin/bash
    command: -c "echo 0"
    # command: /opt/development_download_only.sh
    # these are just examples
    # environment:
    # - osmupdate_extra_params=--base-url=download.geofabrik.de/europe/switzerland-updates/
    # - osm_planet_mirror=http://download.geofabrik.de/
    # - osm_planet_path_relative_to_mirror=europe/switzerland-latest.osm.pbf
    networks:
      - default
    logging:
      <<: *logging
  ##### WORLD PBF UPDATER END ########
volumes:
  # osmaxx
  frontend-database-data: {}
  frontend-media: {}
  frontend-static: {}
  mediator-database-data: {}
  worker-data: {}
  worker-data-ignored: {}
  worker-db: {}
  osm_data: {}
  database-postgis-data: {}
